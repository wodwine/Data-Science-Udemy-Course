{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banned-selling",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You are given data from an Audiobook app. Logically, it relates only to the audio versions of books. Each customer in the database has made a purchase at least once, that's why he/she is in the database. We want to create a machine learning algorithm based on our available data that can predict if a customer will buy again from the Audiobook company.\n",
    "\n",
    "The main idea is that if a customer has a low probability of coming back, there is no reason to spend any money on advertizing to him/her. If we can focus our efforts ONLY on customers that are likely to convert again, we can make great savings. Moreover, this model can identify the most important metrics for a customer to come back again. Identifying new customers creates value and growth opportunities.\n",
    "\n",
    "You have a .csv summarizing the data. There are several variables: Customer ID, Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
    "\n",
    "So these are the inputs (excluding customer ID, as it is completely arbitrary. It's more like a name, than a number).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. So, in fact, we are predicting if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months. 6 months sounds like a reasonable time. If they don't convert after 6 months, chances are they've gone to a competitor or didn't like the Audiobook way of digesting information. \n",
    "\n",
    "The task is simple: create a machine learning algorithm, which is able to predict if a customer will buy again. \n",
    "\n",
    "This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "exciting-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fantastic-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>873</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>611</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>2808</td>\n",
       "      <td>6.66</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>705</td>\n",
       "      <td>324.0</td>\n",
       "      <td>324</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>391</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>819</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1296</td>\n",
       "      <td>7.11</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14079</th>\n",
       "      <td>27398</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>7.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>28220</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081</th>\n",
       "      <td>28671</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>31134</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14083</th>\n",
       "      <td>32832</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14084 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1     2      3      4   5     6     7    8   9    10  11\n",
       "0        873  2160.0  2160  10.13  10.13   0  8.91  0.00  0.0   0    0   1\n",
       "1        611  1404.0  2808   6.66  13.33   1  6.50  0.00  0.0   0  182   1\n",
       "2        705   324.0   324  10.13  10.13   1  9.00  0.00  0.0   1  334   1\n",
       "3        391  1620.0  1620  15.31  15.31   0  9.00  0.00  0.0   0  183   1\n",
       "4        819   432.0  1296   7.11  21.33   1  9.00  0.00  0.0   0    0   1\n",
       "...      ...     ...   ...    ...    ...  ..   ...   ...  ...  ..  ...  ..\n",
       "14079  27398  2160.0  2160   7.99   7.99   0  8.91  0.00  0.0   0   54   0\n",
       "14080  28220  1620.0  1620   5.33   5.33   1  9.00  0.61  0.0   0    4   0\n",
       "14081  28671  1080.0  1080   6.55   6.55   1  6.00  0.29  0.0   0   29   0\n",
       "14082  31134  2160.0  2160   6.14   6.14   0  8.91  0.00  0.0   0    0   0\n",
       "14083  32832  1620.0  1620   5.33   5.33   1  8.00  0.38  0.0   0   90   0\n",
       "\n",
       "[14084 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Audiobooks_data.csv\",header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "according-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11847\n",
       "1     2237\n",
       "Name: 11, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "american-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_all = np.array(data.drop([0,11],axis=1))\n",
    "targets_all = np.array(data[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "expected-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]): # 14084\n",
    "    if targets_all[i]==0:\n",
    "        zero_targets_counter+=1\n",
    "        if zero_targets_counter>num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "inputs_equal_priors = np.delete(inputs_all,indices_to_remove,axis=0)\n",
    "targets_equal_priors = np.delete(targets_all,indices_to_remove,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "embedded-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_counts = inputs_equal_priors.shape[0]\n",
    "\n",
    "shuffled_indices = np.arange(samples_counts)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = inputs_equal_priors[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "premium-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = int(0.8*samples_counts)\n",
    "val_samples = int(0.1*samples_counts)\n",
    "test_samples = samples_counts - train_samples - val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "latest-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train,targets_train = shuffled_inputs[:train_samples],shuffled_targets[:train_samples]\n",
    "inputs_val,targets_val = shuffled_inputs[train_samples:train_samples+val_samples],shuffled_targets[train_samples:train_samples+val_samples]\n",
    "inputs_test,targets_test = shuffled_inputs[train_samples+val_samples:],shuffled_targets[train_samples+val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "grave-footage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3579, 447, 448)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs_train),len(inputs_val),len(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "liquid-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(inputs_train)\n",
    "inputs_train_scaled = scaler.transform(inputs_train)\n",
    "inputs_val_scaled = scaler.transform(inputs_val)\n",
    "inputs_test_scaled = scaler.transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "indian-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data/Audiobooks_data_train\",inputs=inputs_train_scaled,targets=targets_train)\n",
    "np.savez(\"data/Audiobooks_data_val\",inputs=inputs_val_scaled,targets=targets_val)\n",
    "np.savez(\"data/Audiobooks_data_test\",inputs=inputs_test_scaled,targets=targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "prime-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('data/Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "secure-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('data/Audiobooks_data_val.npz')\n",
    "\n",
    "val_inputs = npz['inputs'].astype(np.float)\n",
    "val_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "neutral-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('data/Audiobooks_data_test.npz')\n",
    "\n",
    "test_inputs = npz['inputs'].astype(np.float)\n",
    "test_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "judicial-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 10\n",
    "\n",
    "model = tf.keras.models.Sequential() # Construct model\n",
    "model.add(tf.keras.layers.Dense(units=hidden_layer_size,activation=\"relu\")) # First layer\n",
    "model.add(tf.keras.layers.Dense(units=hidden_layer_size,activation=\"relu\")) # Second layer\n",
    "model.add(tf.keras.layers.Dense(units=output_size,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-newsletter",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "Use \"sparse_categorical_crossentropy\" when the label is integer for two or more label classes, **output_size should be >1**\n",
    "\n",
    "Use \"categorical_crossentropy\" when the label is from one-hot, **output_size should be 1**\n",
    "\n",
    "Use \"binary_crossentropy\" when the label(assumed to be 0 and 1) is integer for only two label classes **output_size should be 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "centered-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((447, 10), (447, 1))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs.shape,val_targets.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "incredible-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.7360 - accuracy: 0.4722 - val_loss: 0.6740 - val_accuracy: 0.5503\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.6392 - accuracy: 0.6030 - val_loss: 0.6064 - val_accuracy: 0.7204\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.5690 - accuracy: 0.7773 - val_loss: 0.5452 - val_accuracy: 0.8054\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.5052 - accuracy: 0.8351 - val_loss: 0.4860 - val_accuracy: 0.8300\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.8533 - val_loss: 0.4350 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8620 - val_loss: 0.3984 - val_accuracy: 0.8479\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.3691 - accuracy: 0.8709 - val_loss: 0.3733 - val_accuracy: 0.8613\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.3468 - accuracy: 0.8776 - val_loss: 0.3576 - val_accuracy: 0.8635\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.3311 - accuracy: 0.8807 - val_loss: 0.3440 - val_accuracy: 0.8702\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.3194 - accuracy: 0.8849 - val_loss: 0.3330 - val_accuracy: 0.8725\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.3098 - accuracy: 0.8871 - val_loss: 0.3248 - val_accuracy: 0.8725\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.3024 - accuracy: 0.8896 - val_loss: 0.3172 - val_accuracy: 0.8770\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2953 - accuracy: 0.8910 - val_loss: 0.3119 - val_accuracy: 0.8837\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2897 - accuracy: 0.8927 - val_loss: 0.3073 - val_accuracy: 0.8837\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2848 - accuracy: 0.8944 - val_loss: 0.3033 - val_accuracy: 0.8814\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2805 - accuracy: 0.8966 - val_loss: 0.2994 - val_accuracy: 0.8881\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2764 - accuracy: 0.8991 - val_loss: 0.2961 - val_accuracy: 0.8881\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2727 - accuracy: 0.8994 - val_loss: 0.2931 - val_accuracy: 0.8881\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2698 - accuracy: 0.9016 - val_loss: 0.2911 - val_accuracy: 0.8881\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.2674 - accuracy: 0.9014 - val_loss: 0.2886 - val_accuracy: 0.8881\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.2644 - accuracy: 0.9025 - val_loss: 0.2883 - val_accuracy: 0.8859\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.2623 - accuracy: 0.9016 - val_loss: 0.2844 - val_accuracy: 0.8904\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.2602 - accuracy: 0.9033 - val_loss: 0.2839 - val_accuracy: 0.8904\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.2582 - accuracy: 0.9033 - val_loss: 0.2823 - val_accuracy: 0.8904\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.2568 - accuracy: 0.9039 - val_loss: 0.2801 - val_accuracy: 0.8881\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.2551 - accuracy: 0.9036 - val_loss: 0.2815 - val_accuracy: 0.8881\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.2535 - accuracy: 0.9042 - val_loss: 0.2781 - val_accuracy: 0.8881\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.2518 - accuracy: 0.9044 - val_loss: 0.2776 - val_accuracy: 0.8926\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.2505 - accuracy: 0.9058 - val_loss: 0.2762 - val_accuracy: 0.8926\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.2491 - accuracy: 0.9061 - val_loss: 0.2758 - val_accuracy: 0.8926\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.2488 - accuracy: 0.9072 - val_loss: 0.2764 - val_accuracy: 0.8926\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.2474 - accuracy: 0.9067 - val_loss: 0.2767 - val_accuracy: 0.8949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc25ebb5250>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "model.fit(x=train_inputs,\n",
    "          y=train_targets,\n",
    "          validation_data=(val_inputs,val_targets),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          callbacks=[early_stopping],\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "twenty-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 934us/step - loss: 0.2844 - accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(x=test_inputs,y=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "toxic-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:0.28, Test accuracy: 88.84%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test loss:{test_loss:.2f}, Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-touch",
   "metadata": {},
   "source": [
    "Using the initial model and hyperparameters given in this notebook, the final test accuracy should be roughly around 91%.\n",
    "\n",
    "Note that each time the code is rerun, we get a different accuracy because each training is different. \n",
    "\n",
    "We have intentionally reached a suboptimal solution, so you can have space to build on it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
